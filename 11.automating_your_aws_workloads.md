# Automating Your AWS Workloads


## Introduction

Automation is a best practice when it comes to designing architectures in the cloud.
Automation allows common tasks to be repeated faster than doing them manually.


Whatever the task, whether simple or complex, automation confers several benefits,
including the following:

* Rapid testing and experimentation
* Reducing expenses
* Minimizing human error
* Rolling back changes safely and completely

Ultimately, automation is about increasing the capacity of the people doing the work
so that they can spend more time being productive and less time fixing problems.


You can deploy automation at different levels of your AWS environment, picking and choosing where it makes the most sense for you. 
You may find it helpful to approach automation in two different ways: 
* imperative and
* declarative.

### The Imperative Approach

The most common example of automation using an imperative approach is scripting, wherein
you use a scripting language such as Bash or PowerShell, or even a tool such as the AWS
Command Line Interface (CLI), to provide the explicit steps necessary to carry out a task.

The imperative approach focuses on the specific step-by-step operations required to carry out a task.

### The Declarative Approach

Using a declarative approach, you write code that declares the desired result of the task,
rather than how to carry it out.

This approach naturally requires
some intelligent software to figure out the operations required to achieve the desired result.


CloudFormation, which is covered in the first part of this chapter, is the most well-known
AWS service that takes a declarative approach to building and configuring your AWS infrastructure.

you write code containing the specifics of the AWS resources you want
and present that code to CloudFormation, and it builds and configures those resources on
your behalf in a matter of seconds.

### Infrastructure as Code

* Using code to define your infrastructure and configurations is commonly called the infrastructure
as code (IaC) approach.

* Defining IaC is a fundamental element of automation in the cloud.

* Because automation relies on code being executed by a machine, it reduces the
risk of human error inherent in carrying out the same work manually.

We cover the following AWS services that enable automation in different
ways:

* CloudFormation—Lets you automate the building and configuration of your AWS
  resources
* The AWS Developer Tools of CodeCommit, CodeBuild, CodeDeploy, and
  CodePipeline—Automate the testing, building, and deployment of applications to
  EC2 and on-premises instances;
* EC2 Auto Scaling—Automatically launches, configures, and terminates EC2 instances
  as needed to meet fluctuating demand
* Systems Manager—Automates common operational tasks such as patching instances
  and backing up Elastic Block Store (EBS) volumes
* OpsWorks—A collection of three different offerings that help automate instance configuration
  and application deployments using the popular Chef and Puppet configuration
  management platforms

## CloudFormation

CloudFormation automatically creates and configures your AWS infrastructure from
code that defines the resources you want it to create and how you want those resources
configured.

### Templates

* The code that defines your resources is stored in text fi les called templates . 
* Templates use the proprietary CloudFormation language, which can be written in JavaScript Object
Notation (JSON) or YAML format.
* Templates contain a description of the AWS resources you want CloudFormation to create,
  so they simultaneously function as infrastructure documentation.
* You can use the same template to build AWS infrastructure repeatedly, such as for
  development or testing.
* You can also use a single template to build many similar environments.
* CloudFormation uses random identifiers when naming resources to ensure the resources it
  creates don’t conflict with each other.
* You can write templates to optionally take parameter inputs, allowing you to customize
  your resources without modifying the original template.

### Stacks

* To provision resources from a template, you must specify a stack name that’s unique within
  your account.
* A stack is a container that organizes the resources described in the template.
* The purpose of a stack is to collectively manage related resources. If you delete
  a stack, CloudFormation automatically deletes all of the resources in it.
* This makes
  CloudFormation perfect for test and development environments that need to be provisioned
  as pristine and then thrown away when no longer needed. Deleting a stack helps ensure
  that all resources are deleted and that no forgotten resources are left lingering, running up
  charges.


#### Stack Updates

* You can have CloudFormation change individual resources in a stack.
* Just modify the template
  to delete, modify, or add resources, and then instruct CloudFormation to perform a
  stack update using the template.
* CloudFormation will automatically update the resources
  accordingly.
* If any other resources are dependent upon a resource that you’ve updated,
CloudFormation will detect that and make sure those downstream resources are also
reconfigured properly.

Alternatively, you can create a change set. Make the desired changes to your template,
and then have CloudFormation generate a change set based on the template.

CloudFormation will let you review the specific changes it will make, and then you can
decide whether to execute those changes or leave everything as is.

A stack policy is a JSON document, separate from a template,
that specifies what resources may be updated. You can use it prevent updates to any or all
resources in a stack. If you absolutely need to update a stack, you can temporarily override
the policy.


#### Tracking Stack Changes

Each stack contains a timestamped record of events that occur within the stack, including
when resources were created, updated, or deleted. This makes it easy to see all changes
made to your stack.

It’s important to understand that resources in CloudFormation stacks can be changed
manually, and CloudFormation doesn’t prevent this. For instance, you can manually delete
a VPC that’s part of a CloudFormation stack. Drift detection is a feature that monitors
your stacks for such changes and alerts you when they occur.


### CloudFormation vs. the AWS CLI

* You can script AWS CLI commands to create resources fast and automatically, but those
  resources won’t be kept in a stack, so you won’t get the same advantages that stacks provide.
* When you’re using the AWS CLI, you can’t update your resources as easily as you can
  with CloudFormation.
* With CloudFormation, you simply adjust the template or parameters
  to change your resources, and CloudFormation figures out how to perform the changes.
* With the AWS CLI, it’s up to you to understand how to change each resource and to ensure
  that a change you make to one resource doesn’t break another.

## AWS Developer Tools

* The AWS Developer Tools are a collection of tools designed to help application developers
  develop, build, test, and deploy their applications onto EC2 and on-premises instances.
* These tools facilitate and automate the tasks that must take place to get a new application
  revision released into production.
* You can use them as part of any IaC approach to automate the deployment and configuration of
  your AWS infrastructure.

You’ll learn about the following AWS Developer Tools:

* CodeCommit
* CodeBuild
* CodeDeploy
* CodePipeline


### CodeCommit

* CodeCommit lets you create private Git repositories that easily integrate with other AWS
  services.
* Git uses a process called versioning, where all changes or commits to a repository are
  retained indefinitely, so you can always revert to an old version of a file if you need it.
* CodeCommit is useful for teams of people who need to collaborate on the same set
  of files, such as developers who collaborate on a shared source code base for an application.
* CodeCommit allows users to check out code by copying or cloning it locally to their
  machine. They make changes to it locally and then check it back in to the repository.

### CodeBuild

* CodeBuild is a fully managed build service. A build is a set of actions performed on source
  code to get it ready for deployment.
* A build could include testing the code for errors or
  transforming it into a machine-readable language, but the specifi c build actions depend on
  the application.

#### Build Actions

* One of the primary purposes of the build process is to run tests against the new code to
  ensure it works properly.
* Automated testing is a key part of a software development practice called continuous
  integration (CI). In CI, developers check their new or modifi ed code into a shared repository
  multiple times a day. A build provider, such as CodeBuild, runs tests against this code.
* build can also consist of compiling source code into a binary such as an executable or
  a package installer. You can even use CodeBuild to create Docker containers and Amazon
  Machine Images (AMIs).
* You define your specific tasks in a build specification fi le that must be included with the
  source code. CodeBuild can get source code from a CodeCommit, GitHub, or Bitbucket
  repository, or an S3 bucket.
* CodeBuild can perform multiple builds simultaneously. Any outputs or artifacts that
  CodeBuild creates are stored in an S3 bucket, making them accessible to the rest of your
  AWS environment.

#### Build Environments

* CodeBuild performs builds in an isolated build environment that runs on a compute
  instance. It creates the build environment before each build and discards it when the build
  is finished.
* This isolation ensures a consistent build process that isn’t affected by leftovers
  from previous builds.
* The build environment always consists of an operating system and a Docker image that
  can include a programming language runtime and tools.
* AWS offers preconfigured build environments for Java, Ruby, Python, Go, Node.js, Android, .NET Core, PHP, and Docker.

You can choose from the following three different compute types for your build
environment:
* build.general1.small—3 GB of memory and 2 vCPU
* build.general1.medium—7 GB of memory and 4 vCPU
* build.general1.large—15 GB of memory and 8 vCPU

### CodeDeploy

CodeDeploy can automatically deploy applications to EC2 instances, the Elastic Container
Service (ECS), Lambda, and even on-premises servers.

CodeDeploy works by pulling source fi les from an S3 bucket, or a GitHub or Bitbucket
repository.

In addition to your application’s source fi les, you must provide an application specification file 
that contains information about how to deploy the application.

#### Deploying to EC2 or On-Premises Instances

* CodeDeploy can deploy applications, scripts, confi guration fi les, and virtually any other
  file to an EC2 or on-premises instance.
* To deploy to an instance, you must install the
  CodeDeploy agent.
* The agent allows the CodeDeploy service to copy fi les to the instance
  and perform deployment tasks on it.
* You can deploy to instances according to specific resource tags, based on Auto Scaling
  Group membership, or by just manually selecting them. 
* You can also control the cadence of deployment by deploying to instances one at a time, all at once, half at a time, or anywhere
  in between.

CodeDeploy supports two different deployment types:

`In-place deployment` An in-place deployment deploys the application to existing instances.
If your application is running, CodeDeploy can stop it, perform any needed cleanup, deploy
the new version, and then restart the application.

`Blue/Green deployment` With a blue/green deployment, CodeDeploy deploys your application
to a new set of instances that you either create manually or have CodeDeploy create
by replicating an existing Auto Scaling group. CodeDeploy then deploys the application to
the new instances. It can also optionally decommission the old instances. If you’re using
an elastic load balancer, CodeDeploy can also automatically redirect traffic to the new
instances.

#### Deploying to ECS

The process for deploying to ECS is almost the same as for deploying to EC2 instances,
except instead of deploying application files to an instance, you deploy Docker images that
run your application in containers.

If you’re doing a deployment upgrade of your application and using an application load
balancer, CodeDeploy can shift the traffic from your old containers to your new ones.

CodeDeploy works with both EC2 and Fargate ECS launch types.


#### Deploying to Lambda

Lambda is Amazon’s serverless computing platform that runs functions that can be written
in a variety of languages.

Because you don’t have to even think about servers when using Lambda, deploying a new
Lambda application with CodeDeploy simply involves creating a new Lambda function.

If you need to update an existing function, CodeDeploy just creates a new version of that
function.

You can then choose how CodeDeploy handles the switchover to the new version.

You can have CodeDeploy shift traffic slowly from one version to the other, or you can do
an immediate, full cutover to the new version.


### CodePipeline

CodePipeline helps orchestrate and automate every task required to move software from
development to production.

* It works by taking your source code and processing it through
  a series of stages, up to and including a deployment stage.
* In between the required source
  and deployment stages, you can add other stages also, such as a build stage that runs tests,
  or an approval stage that requires manual approval before deployment.
* CodeDeploy doesn’t allow deploying
  directly from a CodeCommit repository, but it does allow deploying from an S3
  bucket.
* CodePipeline can automatically take an application in the CodeCommit repository
  and trigger CodeBuild to perform automated testing against it.
* Once the tests pass,
  CodePipeline packages up the application files and places them it into an S3 bucket.
* You can then require manual approval before calling CodeDeploy to deploy the application to
  production.
* Deploying software this way is called continuous delivery.

Each stage consists of one or more actions, and these actions can occur sequentially or
in parallel.

There are six types of actions that you can include in a pipeline:
* Source
* Build
* Test
* Approval
* Deploy
* Invoke

With the exception of the Approval action, each action is performed by a provider that
depending on the action can be an AWS or third-party service:

`Source providers` Source providers include S3, CodeCommit, GitHub, and the Elastic
Container registry (ECR) that stores Docker containers for Elastic Container Service.

`Build and test providers` CodeBuild and third-party tools such as CloudBees, Jenkins, and
TeamCity can provide building and testing services.

`Deploy providers` CodePipeline supports a number of deploy providers. The most common
ones you’re likely to see include the following:
* `CloudFormation` CodePipeline can automatically deploy your AWS infrastructure
  using CloudFormation. For example, developers can create their own template that
  builds a complete test environment. Whenever they update the template, CodePipeline
  can automatically deploy it to CloudFormation. This approach allows developers to create
  their own development infrastructure.
* `CodeDeploy` CodeDeploy can only source application files from GitHub or S3. But you
  can configure CodePipeline to pull files from CodeCommit, package them up, and put
  them in an S3 bucket for CodeDeploy to pick up and deploy.
* `ECS` CodePipeline can deploy Docker containers directly to ECS. By combining this
  with ECR for the source stage, you can use ECR as a source for images, rather than having
  to keep your images in an S3 bucket.
* `S3` Suppose you have a website hosted in S3. You can keep the HTML and other files
  for your website in a CodeCommit repo for versioning. If you want to update your website,
  you make your changes in the repo. CodePipeline detects the change and copies the
  updates to your S3 bucket.

Other supported deploy providers include Elastic Beanstalk, OpsWorks Stacks, the AWS
Service Catalog, and the Alexa Skills Kit.


`Invoke` The Invoke action invokes Lambda functions, and it works only with AWS
Lambda.

`Approval` You can insert manual approvals anywhere in the pipeline after the source stage.


## EC2 Auto Scaling

EC2 Auto Scaling automatically launches preconfigured EC2 instances. The goal of Auto
Scaling is to ensure you have just enough computing resources to meet user demand without
over-provisioning.


### Launch Configurations and Launch Templates

Auto Scaling works by spawning instances from either a launch configuration or a launch
template. For the purposes of Auto Scaling, both achieve the same basic purpose of defining
the instance’s characteristics, such as AMI, disk configuration, and instance type.

* Launch templates are newer and can be used to spawn EC2 instances manually, even without
  Auto Scaling. You can also modify them after you create them.
* Launch configurations,
  on the other hand, can be used only with Auto Scaling. And once you create a launch configuration,
  you can’t modify it.

### Auto Scaling Groups

* Instances created by Auto Scaling are organized into an Auto Scaling group.
* All instances
  in a group can be automatically registered with an application load balancer target group.
* The application load balancer distributes traffic to the instances, spreading the demand out
  evenly among them.

#### Desired Capacity

* When you configure an Auto Scaling group, you define a desired capacity—the number of
  instances that you want Auto Scaling to create.
* Auto Scaling creates this many instances
  and strives to maintain the desired capacity.
* f you raise or lower the capacity, Auto Scaling
  launches or terminates instances to match.

#### Self-Healing

* Failed instances are self-healing. If an instance fails or terminates, Auto Scaling re-creates a
  replacement.
* This way you always get the number of instances you expect.
* Auto Scaling can use EC2 or elastic load balancing (ELB) health checks to determine
  whether an instance is healthy.
* EC2 health checks consider the basic health of an
  instance, whether it’s running, and whether it has network connectivity.
* ELB health
  checks look at the health of the application running on an instance.
* An unhealthy
  instance is treated as a failed instance and is terminated, and Auto Scaling creates
  another in its place.

### Scaling Actions

* Scaling actions control when Auto Scaling launches or terminates instances.
* You control how
  many instances Auto Scaling launches or terminates by specifying a minimum and maximum
  group size.
* Auto Scaling will ensure the number of instances never goes outside of this range.
* Naturally, the desired capacity must rest within the minimum and maximum bounds.

#### Dynamic Scaling

* With dynamic scaling, Auto Scaling launches new instances in response to increased
  demand using a process called scaling out .
* It can also scale in, terminating instances when
  demand ceases.
* You can scale in or out according to a metric, such as average CPU utilization
  of your instances, or based on the number of concurrent application users.

#### Scheduled Scaling

* Instead of or in addition to dynamic scaling, Auto Scaling can scale in or out according to a
  schedule.
* This is particularly useful if your demand has predictable peaks and valleys.
* Predictive scaling is a feature that looks at historic usage patterns and predicts future
  peaks.
* It then automatically creates a scheduled scaling action to match. It needs at least
  one day’s worth of traffi c data to create a scaling schedule.

## Configuration Management

Configuration management is an approach to ensuring accurate and consistent configuration
of your systems.

While automation is concerned with carrying out tasks, configuration
management is primarily concerned with enforcing and monitoring the internal configuration
state of your instances to ensure they’re what you expect.

Such configuration states
primarily include but aren’t limited to operating system configurations and what software
is installed.

As with automation in general, configuration management tools use either imperative
or declarative approaches.

AWS offers both approaches using two tools to help you achieve
configuration management of your EC2 and on-premises instances:

* Systems Manager and
* OpsWorks.

### Systems Manager

Systems Manager uses the imperative approach to get your instances and AWS environment
into the state that you want.


#### Command Documents

Command documents are scripts that run once or periodically that get the system into the
state you want.

Using Command documents, you can install software on an instance, install the latest
security patches, or take inventory of all software on an instance.

Systems Manager can run these periodically, or on a trigger, such as a new instance launch. 

Systems Manager requires an agent to be installed on the instances that you want it to manage.

#### Configuration Compliance

Configuration Compliance is a feature of Systems Manager that can show you whether
instances are in compliance with your desired configuration state

#### Automation Documents

In addition to providing configuration management for instances, Systems Manager lets
you perform many administrative AWS operations you would otherwise perform using
the AWS Management Console or the AWS CLI.

You can use Systems Manager to automatically create
a snapshot of an Elastic Block Store (EBS) volume, launch or terminate an instance, create a
CloudFormation stack, or even create an AMI from an existing EBS volume.


#### Distributor

Using Systems Manager Distributor, you can deploy installable software packages to your
instances. You create a .zip archive containing installable or executable software packages
that your operating system recognizes, put the archive in an S3 bucket, and tell Distributor
where to find it.

Distributor takes care of deploying and installing the software. Distributor
is especially useful for deploying a standard set of software packages that already come as
installers or executables.


### OpsWorks

OpsWorks is a set of three different services that let you take a declarative approach
to configuration management.

OpsWorks uses two popular configuration management platforms that fulfill this requirement:
Chef (https://www.chef.io) and Puppet Enterprise (https://puppet.com).

Puppet and Chef are popular configuration management platforms that can configure
operating systems, deploy applications, create databases, and perform just about any configuration
task you can dream of, all using code.

OpsWorks comes in three different flavors to meet any configuration
management appetite:

* AWS OpsWorks for Puppet Enterprise and AWS OpsWorks for Chef Automate are
  robust and scalable options that let you run managed Puppet or Chef servers on AWS.
* AWS OpsWorks Stacks provides a simple and flexible approach to using configuration
  management just for deploying applications. Instead of going all-in on configuration management,
  you can just use it for deploying and configuring applications.


#### AWS OpsWorks for Puppet Enterprise and AWS OpsWorks for Chef Automate

The high-level architectures of AWS OpsWorks for Puppet Enterprise and Chef Automate
are similar. They consist of at least one Puppet master server or Chef server to communicate
with your managed nodes—EC2 or on-premises instances—using an installed agent.

You define the configuration state of your instances—such as operating system configurations
applications—using Puppet modules or Chef recipes. These contain declarative code,
written in the platform’s domain-specific language, that specifies the resources to provision. 

The code is stored in a central location, such as a Git repository like CodeCommit or an S3 bucket.
OpsWorks manages the servers, but you’re responsible for understanding and operating
the Puppet or Chef software, so you’ll need to know how they work and how to manage
them. 

No worries, though, because both Chef and Puppet have large ecosystems brimming
with off-the-shelf code that can be used for a variety of common scenarios.

#### AWS OpsWorks Stacks

If you like the IaC concept for your applications, but you aren’t familiar with managing
Puppet or Chef servers, you can use AWS OpsWorks Stacks.

OpsWorks Stacks lets you build your application infrastructure in stacks.

A stack is a collection of all the resources your application needs: EC2 instances, databases, application
load balancers, and so on.

Each stack contains at least one layer, which is a container for
some component of your application.

To understand how you might use OpsWorks Stacks, consider a typical database-backed
application that consists of three layers:

* An application layer containing EC2 instances or containers
* A database layer consisting of self-hosted or relational database service (RDS) database
instances
* An application load balancer that distributes traffic to the application layer


There are two basic types of layers that OpsWorks uses: OpsWorks layers and service layers.


`OpsWorks layers` An OpsWorks layer is a template for a set of instances. It specifies
instance-level settings such as security groups and whether to use public IP addresses. It
also includes an auto-healing option that automatically re-creates your instances if they
fail. OpsWorks can also perform load-based or time-based auto scaling, adding more EC2
instances as needed to meet demand.

An OpsWorks layer can provision Linux or Windows EC2 instances, or you can add existing
Linux EC2 or on-premises instances to a stack. OpsWorks Stacks supports Amazon
Linux, Ubuntu Server, CentOS, and Red Hat Enterprise Linux.

To configure your instances and deploy applications, OpsWorks uses the same declarative
Chef recipes as the Chef Automate platform, but it doesn’t provision a Chef server. Instead,
OpsWorks Stacks performs configuration management tasks using the Chef Solo client that
it installs on your instances automatically.


`Service layers` A stack can also include service layers to extend the functionality of your
stack to include other AWS services. Service layers include the following layers:

   `Relational Database Service (RDS)` Using an RDS service layer, you can integrate your
application with an existing RDS instance.

   `Elastic Load Balancing (ELB)` If you have multiple instances in a stack, you can create
an application load balancer to distribute traffic to them and provide high availability.

   `Elastic Container Service (ECS)` Cluster If you prefer to deploy your application to containers
instead of EC2 instances, you can create an ECS cluster layer that connects your
OpsWorks stack to an existing ECS cluster.

## Summary

If there’s one thing that should be clear, it’s that AWS provides many different ways to automate
the same task. The specific services and approaches you should use are architectural
decisions beyond the scope of this book, but you should at least understand how each of the
different AWS services covered in this chapter can enable automation.

Fundamentally, automation entails defining a task as code that a system carries out. This
code can be written as imperative commands that specify the exact steps to perform the
task. The most familiar type of example is the Bash or PowerShell script system administrators
write to perform routine tasks. AWS Systems Manager, CodeBuild, and CodeDeploy
use an imperative approach. Even the Userdata scripts that you use with EC2 Auto Scaling
are imperative.

Code can also be written in a more abstract, declarative form, where you specify the
end result of the task. The service providing the automation translates those declarative
statements into step-by-step operations that it carries out. CloudFormation, OpsWorks for
Puppet Enterprise, OpsWorks for Chef Automate, and OpsWorks Stacks use declarative
languages to carry out automation.

At the end of the day, both the imperative and declarative approaches result in nothing
more than a set of commands that must be carried out sequentially. It’s important to
understand that the imperative and declarative approaches are not opposites. Rather, the
declarative approach abstracts away from you the step-by-step details in favor of a more
results-oriented, user-friendly paradigm. The difference comes down to what approach you
prefer and what the service requires.

Configuration management is a form of automation that emphasizes configuration consistency
and compliance. Naturally, the focus on achieving and maintaining a certain state
lends itself to a declarative approach, so many configuration management platforms such as
Puppet and Chef use declarative language. However, AWS Systems Manager also provides
configuration management, albeit by using an imperative approach.


## Exam Essentials

Know what specific tasks AWS services can automate. CloudFormation can automatically
deploy, change, and even delete AWS resources in one fell swoop.

The AWS Developer Tools—CodeCommit, CodeBuild, CodeDeploy, and CodePipeline—
can help automate some or all of the software development, testing, and deployment process.

EC2 Auto Scaling automatically provisions a set number of EC2 instances. You can optionally
have it scale in or out according to demand or a schedule.

Systems Manager Command documents let you automate tasks against your instance operating
systems, such as patching, installing software, enforcing configuration settings, and
collecting inventory. Automation documents let you automate many administrative AWS
tasks that would otherwise require using the management console or CLI.

OpsWorks for Puppet Enterprise and OpsWorks for Chef Automate also let you configure
your instances and deploy software but do so using the declarative language of Puppet
modules or Chef recipes.

OpsWorks Stacks can automate the build and deployment of an application and its supporting
infrastructure.

`Understand the benefits of automation and infrastructure as code.` Automation allows
common, repetitive tasks to be executed faster than doing them manually and reduces the
risk of human error. When you automate infrastructure builds using code, the code simultaneously
serves as de facto documentation. Code can be placed into version control, making
it easy to track changes and even roll back when necessary.


`Be able to explain the concepts of continuous integration and continuous delivery.` The
practice of continuous integration involves developers regularly checking in code as they
create or change it. An automated process performs build and test actions against it. This
immediate feedback loop allows developers to fix problems quickly and early.


Continuous delivery expands upon continuous integration but includes deploying the application
to production after a manual approval. This effectively enables push-button deployment
of an application to production.