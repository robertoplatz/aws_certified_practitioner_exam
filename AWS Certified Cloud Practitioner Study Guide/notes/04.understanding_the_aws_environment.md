# AWS Certified Practitioner Exam

## Understanding the AWS Environment

### Introduction

* The way you’ll use AWS services for your cloud workloads will be largely defined by the
  way AWS itself organizes its hardware, networking, and security infrastructure.
* So, the best way to learn how to configure things as efficiently and effectively as possible is to
  understand exactly how AWS infrastructure works.
* You’ll learn
  about how—and why—Amazon’s hundreds of globally distributed data centers are divided
  into regions that, in turn, are further divided into Availability Zones.
* You’ll explore how
  you can design your own applications to take the best advantage of those divisions.
* You’ll also learn about how AWS can extend the network reach of your applications
  through its globally distributed edge locations that make up the front end of CloudFront,
  Amazon’s content delivery network (CDN).
* You’ll learn how the ways you use
  and rely on Amazon’s resources are governed by the terms of both the AWS Shared
  Responsibility Model and the AWS Acceptable Use Policy.

### AWS Global Infrastructure: AWS Regions

* AWS performs its cloud magic using hundreds of thousands of servers maintained within
  physical data centers located in a widely distributed set of geographic regions.
* The documentation page at
  https://aws.amazon.com/about-aws/global-infrastructure should always contain the
  latest information available.
* Deploying resources into the U.S. government GovCloud region (or the AWS secret region designed for the U.S.
  intelligence community), for instance, requires special permission.

#### Regionally Based Services

* When you request an instance of an AWS service, the underlying hardware of that instance
  will be carved out of a server running in one—and only one—AWS Region.

* Their underlying physical host can exist in
  no more than one region. Elastic Compute Cloud (EC2) virtual machine instance, its
  Elastic Block Store (EBS) storage volume, a bucket within Simple Storage Service (S3), or
  a new Lambda “serverless” function.


Dividing resources among regions lets you do the following:

* Locate your infrastructure geographically closer to your users to allow access with the
  lowest possible latency
* Locate your infrastructure within national borders to meet regulatory compliance with
  legal and banking rules
* Isolate groups of resources from each other and from larger networks to allow the
  greatest possible security


#### Globally Based Services

* Some AWS resources are not visibly tied to any one region.
* Even if those resources are, technically, running on hardware that must exist within a single region,
  AWS presents them as global.

Here are some examples of global services:
* AWS Identity and Access Management (IAM) is the service for managing the way
  access to your account resources is achieved by way of users and groups, roles, and
  policies.
* Amazon CloudFront is the content delivery network you can use to lower access
  latency for your application users by storing cached versions of frequently requested
  data at AWS edge locations.
* While Amazon S3 buckets must, as we mentioned earlier, exist within a single region,
  S3 is nevertheless considered a global service (open the S3 Console page and look at the
  region indicator).

#### Service Endpoints

To work with or access the resources you’re running within AWS Regions, you’ll have to
know how they’re identified.

* The correct endpoint for an EC2 instance in the us-east-1 (Northern Virginia) region would be ec2.us-east-1.amazonaws.com
* The endpoint for the Amazon Relational Database Service (RDS) in the eu-west-3 (Paris)
  region is rds.eu-west-3.amazonaws.com
* The complete list of endpoints for all AWS services, see this page: https://docs.aws.amazon.com/general/latest/gr/rande.html


### AWS Global Infrastructure: Availability Zones

* An AWS Region (with the current exception of the Osaka-Local region) encompasses at
  least two distinct Availability Zones connected to each other with low-latency network
  links.
* Although, for security reasons, Amazon zealously guards the street addresses of its
  data centers, we do know that a single AZ is made up of at least one fully independent data
  center that’s built on hardware and power resources used by no other AZ.
* The advantage of this level of separation is that if one AZ loses power or suffers some
  kind of catastrophic outage, the chances of it spreading to a second AZ in the region are
  minimal.
* You can assume that no two AZs will ever share resources from a single physical
  data center.

#### Availability Zone Designations

* Before launching an EC2 instance, for example, you’ll need to specify a network subnet
  associated with an AZ.
* It’s the subnet/AZ combination that will be your instance’s host
  environment.
* For now, though, you should be aware of how AZs are identified within the AWS
  resource configuration process.
* us-east-1a would be the first
  AZ within the us-east-1 region, and us-east-1d would be the fourth.
* You may have noticed that the AZs weren’t listed in order in the subnet drop-down
  menu.
* The problem with consistently listing the AZs in order is that the vast majority of users
  would always go for us-east-1a.
* But launching so many resources in just that first AZ
  would place unmanageable stress on the resources in poor old us-east-1a and leave all the
  others underutilized.
* So, Amazon solves the problem by displaying the AZs out of order.


#### Availability Zone Networking

* You’ll only get the full value out of the resources you run within an AWS Region by properly
  organizing them into network segments (or subnets).
* You can isolate your production servers from your development and staging servers to ensure that
  there’s no leakage between them.
* This can free your developers to confidently experiment
  with configuration profiles without having to worry about accidentally bringing down your
  public-facing application.
* Distributing production workloads among multiple subnets can
  also make your applications more highly available and fault tolerant.
* A subnet is really nothing more than a single block of Internet Protocol (IP) addresses.
* Calculating netmasks for those ranges to properly understand their Classless Inter-
  Domain Routing (CIDR) notation

#### Availability Zones and High Availability

* One of the key principles underlying the entire business of server administration is that all
  hardware (and most software) will eventually fail.
* A resource running without backup is known as a single point of failure.
* The only effective protection against failure is redundancy, which involves provisioning
  two or more instances of whatever your workload requires rather than just one.
* But it’s not enough to run parallel resources if they’re going to be sitting right next to each other in the
  same data center.
* So, you’ll also need to distribute your resources across remote locations.
* Since the AWS cloud is already available within dozens and dozens of Availability Zones
  spread across all continents (besides, for now at least, Antarctica), deploying or, at least,
  preparing quick-launch templates for remote backup instances is easy.

AWS slays the application failure dragon using autoscaling
and load balancing:
* Autoscaling can be configured to replace or replicate a resource to ensure that a predefined
  service level is maintained regardless of changes in user demand or the availability
  of existing resources.
* Load balancing orchestrates the use of multiple parallel resources to direct user
  requests to the server resource that’s best able to provide a successful experience. A
  common use case for load balancing is to coordinate the use of primary and (remote)
  backup resources to cover for a failure.


### AWS Global Infrastructure: Edge Locations

#### Edge Locations and CloudFront

* An edge location is a site where AWS deploys physical server infrastructure to provide lowlatency
  user access to Amazon-based data.
* Perhaps the best-known tenant of edge locations is CloudFront, Amazon’s CDN service.
* How does that work? Let’s say you’re hosting large media fi les in S3 buckets.
* If users would have to retrieve their fi les directly from the bucket each time they were requested,
  delivery—especially to end users living continents away from the bucket location—would
  be relatively slow.
* But if you could store cached copies of the most popular fi les on servers
  located geographically close to your users, then they wouldn’t have to wait for the original
  fi le to be retrieved but could be enjoying the cached copy in a fraction of the time.

#### Regional Edge Cache Locations

* In addition to the fleet of regular edge locations, Amazon has further enhanced CloudFront
  functionality by adding what it calls a regional edge cache.
* The idea is that CloudFrontserved
  objects are maintained in edge location caches only as long as there’s a steady flow
  of requests. Once the rate of new requests drops off, an object will be deleted from the
  cache, and future requests will need to travel all the way back to the origin server (like an
  S3 bucket).
* There are currently nine worldwide;


### The AWS Shared Responsibility Model

* The AWS cloud—like any large and complex environment—is built on top of a stack of
  rules and assumptions.
* The success of your AWS projects will largely depend on how well
  you understand those rules and assumptions and on how fully you adopt the practices that
  they represent.
* The AWS Shared Responsibility Model is a helpful articulation of those
  rules and assumptions, and it’s worth spending some time thinking about it.
* Amazon distinguishes between the security and reliability of the cloud, which is its
  responsibility, and the security and reliability of what’s in the cloud, which is up to you,
  the customer.
* AWS is responsible for making sure that its locations are
  secure, reliably powered, and properly maintained.
* AWS is also on the hook for patching,
  encrypting (where relevant), and maintaining the operating systems and virtualization
  software running its physical servers and for the software running its managed
  services.


### The AWS Shared Responsibility Model

What exactly is “managed” and what’s “unmanaged”?

![img.png](https://github.com/robertoplatz/aws_certified_practitioner_exam/blob/main/AWS%20Certified%20Cloud%20Practitioner%20Study%20Guide/notes/images/responsability.png?raw=true)

Figure 4.4 illustrates the way responsibility for the integrity and security of AWS infrastructure
is divided between Amazon and its customers.

![img.png](https://github.com/robertoplatz/aws_certified_practitioner_exam/blob/main/AWS%20Certified%20Cloud%20Practitioner%20Study%20Guide/notes/images/shared_responsability_model.png?raw=true)

#### Managed Resources

* A managed cloud service will “hide” all or some of the underlying configuration and
  administration work needed to keep things running, leaving you free to focus on the “business”
  end of your project.
* For example, an application running on an EC2 instance might
  need a database in the backend. You could install and configure a MySQL database engine
  on the instance itself, but you’d be responsible for patches, updates, and all the regular care
  and feeding (not to mention letting it out for its morning walks).
* Alternatively, you could point your application to a stand-alone database you launch
  on Amazon’s Relational Database Service (RDS). AWS is responsible for patching an RDS
  database and ensuring its data is secure and reliable. You only need to worry about populating
  the database and connecting it to your application.
* RDS, therefore, is a good example of a partially managed service.
* Elastic Beanstalk, which hides just about all the complexity of its runtime environment, leaving nothing for you to do beyond
  uploading your application code.
* Beanstalk handles the instances, storage, databases, and
  networking headaches—including ongoing patches and administration—invisibly.

#### Unmanaged Resources

* The most obvious example of an unmanaged AWS service is EC2.
* You’re expected to care for the operating system and everything that’s running
  on it exactly the way you would for a physical server in your on-premises data center.
* even EC2 can’t be said to be entirely unmanaged since the integrity of the physical
  server that hosts it is, of course, the responsibility of AWS.
* Some cloud operations will demand greater involvement from you and your administration team, and some will
  demand less.
* The key—especially during a project’s planning stages—is to be aware of your responsibilities and to
  always make security a critical priority.

#### Service Health Status

* AWS makes regularly updated, region-by-region reports on the status of its services publicly available.
* Any service outages that could affect the
  performance of anyone’s workload will appear on Amazon’s Service Health Dashboard
  (https://status.aws.amazon.com)—often within a minute or two of the outage hitting.
* While configuration errors are always a possible cause of a failure in your infrastructure,
  you should always make the Service Health Dashboard one of your first stops whenever you
  dive into a troubleshooting session.


#### AWS Acceptable Use Policy

* The AWS Acceptable Use Policy (https://aws.amazon.com/aup) makes it abundantly clear
  that it does not permit the use of its infrastructure in any illegal, harmful, or offensive way.
* Amazon reserves the right to suspend or even terminate your use of its services should you
  engage in illegal, insecure, or abusive activities (including the sending of spam and related mass
  mailings).
* Even running penetration testing operations against your own AWS infrastructure
  can cause you trouble if you don’t get explicit permission from Amazon in advance.

### Summary

* An AWS Region connects at least two Availability Zones located within a single geographic
  area into a low-latency network.
* Because of the default isolation of their underlying hardware,
  building secure, access-controlled regional environments is eminently possible.
* An Availability Zone is a group of one or more independent (and fault-protected) data
  centers located within a single geographic region.
* AWS offers some global resources whose use isn’t restricted to any one region. Those
  include IAM, CloudFront, and S3.
* You can connect to AWS service instances using their endpoint addresses, which will
  (generally) incorporate the host region’s designation.
* EC2 virtual machine instances are launched with an IP address issued from a network
  subnet that’s associated with a single Availability Zone.
* The principle of high availability can be used to make your infrastructure more resilient
  and reliable by launching parallel redundant instances in multiple Availability Zones.
* AWS edge locations are globally distributed data servers that can store cached copies of
  AWS-based data from which—on behalf of the CloudFront service—they can be efficiently
  served to end users.
* The elements of the AWS platform that you’re expected to secure and maintain and
  those whose administration is managed by Amazon are defined by the AWS Shared
  Responsibility Model.


### Exam Essentials

**Understand the importance of resource isolation for cloud deployments.**
Properly placing your cloud resources within the right region and Availability Zone—along with carefully setting
appropriate access controls—can improve both application security and performance.


**Understand the role of autoscaling in a highly available deployment.** 
The scalability of AWS resources means you can automate the process of increasing or decreasing the scale of
a deployment based on need. This can automate application recovery after a crash.
Understand the role of load balancing in a highly available deployment. The ability to
automatically redirect incoming requests away from a nonfunctioning instance and to a
backup replacement is managed by a load balancer.


**Understand the principles of the AWS Shared Responsibility Model.**

AWS handles security and administration for its underlying physical infrastructure and for the full stack of
all its managed services, while customers are responsible for everything else.

**Understand the principles of the AWS Acceptable Use Policy.** 

Using AWS resources to commit crimes or launch attacks against any individual or organization will result in
account suspension or termination.